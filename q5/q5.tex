\documentclass[12pt,a4paper]{article}
% Encoding + Language
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
% Math
\usepackage{amsmath, amsfonts, amssymb, amsthm}
\usepackage{mathtools}
% Graphics & Figures
\usepackage{graphicx}
\usepackage{float} % allows [H] for figures
% Page Layout
\usepackage{geometry}
\geometry{margin=1in}
% Colors
\usepackage{xcolor}

\title{Natural Language Processing - Assignment 2}
% ---------------------------------------------------------

\begin{document}

\maketitle

\newpage

\section{Question 5: Sentiment Analysis}

\subsection{Part (a) - T5 Paper Research}

\subsubsection{GitHub Repository}
The GitHub repository for the T5 project is:
\begin{center}
\texttt{https://github.com/google-research/text-to-text-transfer-transformer}
\end{center}

\noindent\textbf{Source:} T5 Paper, page 1, footnote 1.

\subsubsection{Models Made Publicly Available}
The authors released five pre-trained T5 model variants with different sizes:

\begin{itemize}
    \item \textbf{T5-Small}: 60 million parameters
    \item \textbf{T5-Base}: 220 million parameters
    \item \textbf{T5-Large}: 770 million parameters
    \item \textbf{T5-3B}: 3 billion parameters
    \item \textbf{T5-11B}: 11 billion parameters
\end{itemize}

\noindent\textbf{Source:} GitHub README.md, section ``Released Model Checkpoints''.

\subsubsection{Dataset for Sentiment Analysis Benchmark}
The dataset used to benchmark sentiment analysis in the T5 paper is \textbf{SST-2 (Stanford Sentiment Treebank-2)}, which is part of the GLUE benchmark suite. SST-2 is a binary sentiment classification task.

\noindent\textbf{Source:} T5 Paper, Section 2.3 ``Downstream Tasks'', GLUE benchmark description.

\subsubsection{Evaluation Metric}
The evaluation metric used for the sentiment analysis task (SST-2) is \textbf{Accuracy}. The model's predictions are compared against the ground truth labels, and the percentage of correct predictions is reported.

\noindent\textbf{Source:} T5 Paper, Table 1 (results table), column header ``SST-2: Acc''.

\subsection{Part (b) - T5-Small Model Fine-tuned on SST2}

\subsubsection{Selected Model}
The selected model for this assignment is:
\begin{center}
\textbf{\texttt{lightsout19/t5-sst2}}
\end{center}

This model is a T5 variant that has been fine-tuned on the SST-2 dataset for sentiment classification.

\noindent\textbf{Source:} Hugging Face Model Hub - \texttt{https://huggingface.co/lightsout19/t5-sst2}

\subsubsection{Model Details}
\begin{itemize}
    \item \textbf{Base Architecture}: T5 (Text-to-Text Transfer Transformer)
    \item \textbf{Fine-tuning Dataset}: SST-2 (Stanford Sentiment Treebank-2)
    \item \textbf{Task}: Binary sentiment classification
    \item \textbf{Framework}: Transformers library (PyTorch/TensorFlow compatible)
    \item \textbf{Usage}: Can be loaded using \texttt{AutoTokenizer} and \texttt{AutoModelForSequenceClassification}
\end{itemize}

\subsubsection{Alternative Models Considered}
During the model selection process, the following alternatives were also identified:

\begin{enumerate}
    \item \textbf{\texttt{hyyoka/t5-small-finetuned-sst2}}: A T5-Small model (60.5M parameters) specifically fine-tuned on SST-2. This model exactly matches the T5-Small size specification.
    
    \item \textbf{\texttt{google/flan-t5-small}}: An improved version of T5-Small (77M parameters) that has been instruction fine-tuned on 1000+ tasks. While not specifically fine-tuned on SST-2, FLAN-T5 shows improved performance across many NLP tasks including sentiment analysis.
\end{enumerate}

\noindent\textbf{Source:} Hugging Face Model Hub searches for ``t5-small sst2'' and ``flan-t5-small''.

\end{document}
